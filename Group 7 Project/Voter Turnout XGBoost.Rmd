---
title: "Voter Turnout XGBoost"
author: "Anvita Kallam"
date: "2024-07-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, fig.width=8, fig.height=4)
options(scipen = 999, digits = 3)  # controls base R output

# Package setup
if(!require("pacman")) install.packages("pacman")

pacman::p_load(car, tidyverse, dplyr, DiagrammeR, ggplot2, data.table, lubridate, 
               glmnet, kableExtra, stargazer, scales, viridis, knitr, readr, xgboost, Matrix, usmap)
```

## Setup

```{r}

library(caret)
library(xgboost)
library(Matrix)


data1 <- read.csv('data/TurnoutFinal.csv')


data1$State <- as.factor(data1$State)
data1$Gov_Party <- as.factor(data1$Gov_Party)


dummies <- dummyVars(~ ., data = data1)
data1_transformed <- predict(dummies, newdata = data1)


X <- data1_transformed
y <- data1$Turnout

X <- X[, colnames(X) != "Turnout"]


set.seed(20)
trainIndex <- createDataPartition(y, p = .7, list = FALSE, times = 1)
X_train_test <- X[trainIndex, ]
X_val <- X[-trainIndex, ]
y_train_test <- y[trainIndex]
y_val <- y[-trainIndex]

set.seed(20)
trainIndex2 <- createDataPartition(y_train_test, p = .5, list = FALSE, times = 1)
X_train <- X_train_test[trainIndex2, ]
X_test <- X_train_test[-trainIndex2, ]
y_train <- y_train_test[trainIndex2]
y_test <- y_train_test[-trainIndex2]


```

## XGBoost

New model to use

```{r}


dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dval <- xgb.DMatrix(data = as.matrix(X_val), label = y_val)


params <- list(
  objective = "reg:squarederror", 
  eta = 0.3,                       
  max_depth = 15,             
  subsample = 0.8,          
  colsample_bytree = 0.8
)

set.seed(20)
fit_xgb <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 50, 
  watchlist = list(train = dtrain, val = dval),
  early_stopping_rounds = 5,      
  print_every_n = 10              
)


predictions_xgb <- predict(fit_xgb, newdata = dval)


mse_xgb <- sqrt(mean((predictions_xgb - y_val)^2))
cat("Root MSE of the XGBoost model: ", mse_xgb, "\n")


```
```{r}

importance_matrix <- xgb.importance(model = fit_xgb)

xgb.plot.importance(importance_matrix, top_n = 20)


xgb.plot.tree(model = fit_xgb, trees = 2)

```

```{r}

sum((predictions_xgb - y_val)^2)

```