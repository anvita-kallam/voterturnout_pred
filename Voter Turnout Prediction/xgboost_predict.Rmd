---
title: "Voter Turnout XGBoost"
author: "Anvita Kallam"
date: "2024-07-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 4)
options(scipen = 999, digits = 3)  # controls base R output

# Package setup
if(!require("pacman")) install.packages("pacman")
pacman::p_load(car, tidyverse, dplyr, DiagrammeR, ggplot2, data.table, lubridate, 
               glmnet, kableExtra, stargazer, scales, viridis, knitr, readr, xgboost, Matrix, usmap)

```


```{r}
library(caret)
library(xgboost)
library(Matrix)

# Load the data
data1 <- read.csv('data/TurnoutFinal.csv')
predict_data <- read.csv('data/Predict.csv')

# Convert necessary columns to factors
data1$State <- as.factor(data1$State)
data1$Gov_Party <- as.factor(data1$Gov_Party)
predict_data$State <- as.factor(predict_data$State)
predict_data$Gov_Party <- as.factor(predict_data$Gov_Party)

# Create dummy variables for training data
dummies <- dummyVars(~ ., data = data1)
data1_transformed <- predict(dummies, newdata = data1)

X <- data1_transformed
y <- data1$Turnout

X <- X[, colnames(X) != "Turnout"]

# Split the data into training and validation sets
set.seed(20)
trainIndex <- createDataPartition(y, p = .7, list = FALSE, times = 1)
X_train_test <- X[trainIndex, ]
X_val <- X[-trainIndex, ]
y_train_test <- y[trainIndex]
y_val <- y[-trainIndex]

set.seed(20)
trainIndex2 <- createDataPartition(y_train_test, p = .5, list = FALSE, times = 1)
X_train <- X_train_test[trainIndex2, ]
X_test <- X_train_test[-trainIndex2, ]
y_train <- y_train_test[trainIndex2]
y_test <- y_train_test[-trainIndex2]

```

```{r}
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dval <- xgb.DMatrix(data = as.matrix(X_val), label = y_val)

params <- list(
  objective = "reg:squarederror", 
  eta = 0.3,                       
  max_depth = 15,             
  subsample = 0.8,          
  colsample_bytree = 0.8
)

set.seed(20)
fit_xgb <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 50, 
  watchlist = list(train = dtrain, val = dval),
  early_stopping_rounds = 5,      
  print_every_n = 10              
)

predictions_xgb <- predict(fit_xgb, newdata = dval)
mse_xgb <- sqrt(mean((predictions_xgb - y_val)^2))
cat("Root MSE of the XGBoost model: ", mse_xgb, "\n")
```

```{r}
# Transform the prediction data
predict_data_transformed <- predict(dummies, newdata = predict_data)

# Ensure the prediction data has all the necessary columns
missing_cols <- setdiff(colnames(X_train), colnames(predict_data_transformed))
for (col in missing_cols) {
  predict_data_transformed[[col]] <- 0
}

# Reorder columns to match the training data
predict_data_transformed <- predict_data_transformed[, colnames(X_train)]

# Make predictions
dpredict <- xgb.DMatrix(data = as.matrix(predict_data_transformed))
predictions_2024 <- predict(fit_xgb, newdata = dpredict)

predictions_2024
```

```{r}

predict_data$Predicted_Turnout <- predictions_2024

#write.csv(predict_data, 'data/Predict_with_Predictions.csv', row.names = FALSE)

```

```{r}

library(ggplot2)
library(usmap)
library(viridis)

predict_data <- read.csv('data/VoterTurnoutDataset - xgboost_predictions.csv')

# predict_data <- predict_data %>%
#   rename(state = States)

# Ensure that the state abbreviations in the data are in uppercase to match with usmap data
predict_data$State <- toupper(predict_data$State)

# Plot the heatmap
plot_usmap(regions = "state", data = predict_data, values = "Predicted_Turnout") +
    scale_fill_viridis(option = "magma", direction = -1, name = "Predicted Turnout", 
      limits = c(38.3, 74.8)) +
    theme(legend.position = "right") +
    ggtitle("Voter Turnout Rate by State 2024")

```